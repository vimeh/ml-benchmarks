{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Benchmarking.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZA7+k0k6a3FhCg1qUeFMc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "17fcd95a862c4e34824dbae136103347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30ed27d5ec674aeebde84b67ed9dd290",
              "IPY_MODEL_475663d0c8c24ac6a27c2aa7217b639c",
              "IPY_MODEL_a65ae97bcb3c49189ff9b0a304092bbd"
            ],
            "layout": "IPY_MODEL_1c837e19a8bf470d89f4d1a6597adef2"
          }
        },
        "30ed27d5ec674aeebde84b67ed9dd290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb0130207bac44c295c42d80b138053d",
            "placeholder": "​",
            "style": "IPY_MODEL_b1779f9b6795448094d9ff1092122922",
            "value": "Downloading: 100%"
          }
        },
        "475663d0c8c24ac6a27c2aa7217b639c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9216135caa4149aa8345be780cba2b84",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f893084549ba42fdb1897a276ffca601",
            "value": 483
          }
        },
        "a65ae97bcb3c49189ff9b0a304092bbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d85e47025aa49ef8cbaf754c0d08094",
            "placeholder": "​",
            "style": "IPY_MODEL_e607fc8148f3426a9481148064eb0255",
            "value": " 483/483 [00:00&lt;00:00, 10.9kB/s]"
          }
        },
        "1c837e19a8bf470d89f4d1a6597adef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb0130207bac44c295c42d80b138053d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1779f9b6795448094d9ff1092122922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9216135caa4149aa8345be780cba2b84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f893084549ba42fdb1897a276ffca601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d85e47025aa49ef8cbaf754c0d08094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e607fc8148f3426a9481148064eb0255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f208a031236440aaae60516986f95c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c90989add43246d996ffaebdda41715d",
              "IPY_MODEL_b6479404ebb34d3eb541373c71e28ca7",
              "IPY_MODEL_a020b455a9d746e187079b03773bfe9b"
            ],
            "layout": "IPY_MODEL_8133034fbcf74b3f86d1c1c505c12a7d"
          }
        },
        "c90989add43246d996ffaebdda41715d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0ee8c0572da4a6592f2f4155f9535fc",
            "placeholder": "​",
            "style": "IPY_MODEL_95d3467536a84b3fad2fb98dcb8fd8c3",
            "value": "Downloading: 100%"
          }
        },
        "b6479404ebb34d3eb541373c71e28ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86ea0796a7b84967afe4c21f56f23dff",
            "max": 363423424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eed0ecf6721041d1ac7241f01ecc9a63",
            "value": 363423424
          }
        },
        "a020b455a9d746e187079b03773bfe9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_319843863edf4b2b9ad93210a7ee14b3",
            "placeholder": "​",
            "style": "IPY_MODEL_435455d45d4049f88d961867e0289588",
            "value": " 347M/347M [00:15&lt;00:00, 28.0MB/s]"
          }
        },
        "8133034fbcf74b3f86d1c1c505c12a7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0ee8c0572da4a6592f2f4155f9535fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95d3467536a84b3fad2fb98dcb8fd8c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86ea0796a7b84967afe4c21f56f23dff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eed0ecf6721041d1ac7241f01ecc9a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "319843863edf4b2b9ad93210a7ee14b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "435455d45d4049f88d961867e0289588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj3-UCcxQCcQ",
        "outputId": "bba254e9-1144-4f13-e819-0f70824b2728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Mar 29 20:16:13 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    33W / 250W |  15991MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /etc/os-release"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN-OGJq7UcCQ",
        "outputId": "7a10936a-8b9f-4fb6-9c8f-dc8726410f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME=\"Ubuntu\"\n",
            "VERSION=\"18.04.5 LTS (Bionic Beaver)\"\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "PRETTY_NAME=\"Ubuntu 18.04.5 LTS\"\n",
            "VERSION_ID=\"18.04\"\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "VERSION_CODENAME=bionic\n",
            "UBUNTU_CODENAME=bionic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.version.VERSION)"
      ],
      "metadata": {
        "id": "guW-xwD9UuPr",
        "outputId": "b6139cd3-f792-473b-86e5-412c21e13ad9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa541-c9ObnM",
        "outputId": "7745b35d-bccc-4e3a-a12d-6853a2eed523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 22.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 16.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TensorFlow Benchmarks**"
      ],
      "metadata": {
        "id": "4rPCuXZC98Wp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "17fcd95a862c4e34824dbae136103347",
            "30ed27d5ec674aeebde84b67ed9dd290",
            "475663d0c8c24ac6a27c2aa7217b639c",
            "a65ae97bcb3c49189ff9b0a304092bbd",
            "1c837e19a8bf470d89f4d1a6597adef2",
            "fb0130207bac44c295c42d80b138053d",
            "b1779f9b6795448094d9ff1092122922",
            "9216135caa4149aa8345be780cba2b84",
            "f893084549ba42fdb1897a276ffca601",
            "5d85e47025aa49ef8cbaf754c0d08094",
            "e607fc8148f3426a9481148064eb0255",
            "f208a031236440aaae60516986f95c9e",
            "c90989add43246d996ffaebdda41715d",
            "b6479404ebb34d3eb541373c71e28ca7",
            "a020b455a9d746e187079b03773bfe9b",
            "8133034fbcf74b3f86d1c1c505c12a7d",
            "e0ee8c0572da4a6592f2f4155f9535fc",
            "95d3467536a84b3fad2fb98dcb8fd8c3",
            "86ea0796a7b84967afe4c21f56f23dff",
            "eed0ecf6721041d1ac7241f01ecc9a63",
            "319843863edf4b2b9ad93210a7ee14b3",
            "435455d45d4049f88d961867e0289588"
          ]
        },
        "id": "20zzwA-upLW_",
        "outputId": "bd9ff04f-9146-4e8c-ef38-d35d123ae3ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating synthetic data: 100%|██████████| 16/16 [00:18<00:00,  1.16s/folders]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST: resnet50v2 at b=32\n",
            "Found 2048 files belonging to 16 classes.\n",
            "Epoch 1/2\n",
            "64/64 [==============================] - 43s 146ms/step - loss: 2.9290\n",
            "Epoch 2/2\n",
            "64/64 [==============================] - 10s 146ms/step - loss: 2.7545\n",
            "Epoch 1/3\n",
            "64/64 [==============================] - 10s 151ms/step - loss: 2.5997\n",
            "Epoch 2/3\n",
            "64/64 [==============================] - 10s 146ms/step - loss: 2.4517\n",
            "Epoch 3/3\n",
            "64/64 [==============================] - 10s 147ms/step - loss: 2.2174\n",
            "32: 205.3\n",
            "TEST: resnet50v2 at b=64\n",
            "Found 2048 files belonging to 16 classes.\n",
            "Epoch 1/2\n",
            "32/32 [==============================] - 33s 974ms/step - loss: 1.2612\n",
            "Epoch 2/2\n",
            "32/32 [==============================] - 9s 263ms/step - loss: 0.1701\n",
            "Epoch 1/3\n",
            "32/32 [==============================] - 9s 262ms/step - loss: 0.0350\n",
            "Epoch 2/3\n",
            "32/32 [==============================] - 9s 263ms/step - loss: 0.0089\n",
            "Epoch 3/3\n",
            "32/32 [==============================] - 9s 263ms/step - loss: 0.0027\n",
            "64: 217.0\n",
            "TEST: resnet50v2 at b=128\n",
            "Found 2048 files belonging to 16 classes.\n",
            "Epoch 1/2\n",
            "16/16 [==============================] - 37s 2s/step - loss: 9.6242e-04\n",
            "Epoch 2/2\n",
            "16/16 [==============================] - 9s 508ms/step - loss: 7.8758e-04\n",
            "Epoch 1/3\n",
            "16/16 [==============================] - 9s 508ms/step - loss: 6.8352e-04\n",
            "Epoch 2/3\n",
            "16/16 [==============================] - 9s 507ms/step - loss: 6.5567e-04\n",
            "Epoch 3/3\n",
            "16/16 [==============================] - 9s 508ms/step - loss: 5.4293e-04\n",
            "128: 206.3\n",
            "TEST: resnet50v2 at b=256\n",
            "Found 2048 files belonging to 16 classes.\n",
            "Epoch 1/2\n",
            "FAILED: resnet50v2 at b=256 OOM\n",
            "TEST: distilbert-base-uncased at b=16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17fcd95a862c4e34824dbae136103347"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/347M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f208a031236440aaae60516986f95c9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'vocab_transform', 'vocab_layer_norm', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_19', 'pre_classifier', 'classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_distil_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " distilbert (TFDistilBertMai  multiple                 66362880  \n",
            " nLayer)                                                         \n",
            "                                                                 \n",
            " pre_classifier (Dense)      multiple                  590592    \n",
            "                                                                 \n",
            " classifier (Dense)          multiple                  6152      \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,959,624\n",
            "Trainable params: 66,959,624\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "64/64 - 20s - loss: 0.4715 - 20s/epoch - 307ms/step\n",
            "Epoch 2/2\n",
            "64/64 - 5s - loss: 7.1526e-07 - 5s/epoch - 85ms/step\n",
            "Epoch 1/3\n",
            "64/64 - 5s - loss: 7.1526e-07 - 5s/epoch - 86ms/step\n",
            "Epoch 2/3\n",
            "64/64 - 5s - loss: 7.1526e-07 - 5s/epoch - 86ms/step\n",
            "Epoch 3/3\n",
            "64/64 - 5s - loss: 7.1526e-07 - 5s/epoch - 86ms/step\n",
            "16: 149.8\n",
            "TEST: distilbert-base-uncased at b=32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'vocab_transform', 'vocab_layer_norm', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'dropout_39', 'classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_distil_bert_for_sequence_classification_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " distilbert (TFDistilBertMai  multiple                 66362880  \n",
            " nLayer)                                                         \n",
            "                                                                 \n",
            " pre_classifier (Dense)      multiple                  590592    \n",
            "                                                                 \n",
            " classifier (Dense)          multiple                  6152      \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,959,624\n",
            "Trainable params: 66,959,624\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "64/64 - 22s - loss: 0.0271 - 22s/epoch - 343ms/step\n",
            "Epoch 2/2\n",
            "64/64 - 10s - loss: 7.1526e-07 - 10s/epoch - 162ms/step\n",
            "Epoch 1/3\n",
            "64/64 - 10s - loss: 7.1526e-07 - 10s/epoch - 162ms/step\n",
            "Epoch 2/3\n",
            "64/64 - 10s - loss: 7.1526e-07 - 10s/epoch - 162ms/step\n",
            "Epoch 3/3\n",
            "64/64 - 10s - loss: 7.1526e-07 - 10s/epoch - 162ms/step\n",
            "32: 197.4\n",
            "TEST: distilbert-base-uncased at b=64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'vocab_transform', 'vocab_layer_norm', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_59', 'pre_classifier', 'classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_distil_bert_for_sequence_classification_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " distilbert (TFDistilBertMai  multiple                 66362880  \n",
            " nLayer)                                                         \n",
            "                                                                 \n",
            " pre_classifier (Dense)      multiple                  590592    \n",
            "                                                                 \n",
            " classifier (Dense)          multiple                  6152      \n",
            "                                                                 \n",
            " dropout_59 (Dropout)        multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,959,624\n",
            "Trainable params: 66,959,624\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "64/64 - 34s - loss: 0.0234 - 34s/epoch - 533ms/step\n",
            "Epoch 2/2\n",
            "64/64 - 20s - loss: 8.3446e-07 - 20s/epoch - 317ms/step\n",
            "Epoch 1/3\n",
            "64/64 - 20s - loss: 8.3446e-07 - 20s/epoch - 318ms/step\n",
            "Epoch 2/3\n",
            "64/64 - 20s - loss: 8.3446e-07 - 20s/epoch - 317ms/step\n",
            "Epoch 3/3\n",
            "64/64 - 20s - loss: 8.3446e-07 - 20s/epoch - 317ms/step\n",
            "64: 149.9\n",
            "TEST: distilbert-base-uncased at b=128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'vocab_transform', 'vocab_layer_norm', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'dropout_79', 'classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_distil_bert_for_sequence_classification_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " distilbert (TFDistilBertMai  multiple                 66362880  \n",
            " nLayer)                                                         \n",
            "                                                                 \n",
            " pre_classifier (Dense)      multiple                  590592    \n",
            "                                                                 \n",
            " classifier (Dense)          multiple                  6152      \n",
            "                                                                 \n",
            " dropout_79 (Dropout)        multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,959,624\n",
            "Trainable params: 66,959,624\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "64/64 - 52s - loss: 0.1730 - 52s/epoch - 806ms/step\n",
            "Epoch 2/2\n",
            "64/64 - 38s - loss: 8.3446e-07 - 38s/epoch - 587ms/step\n",
            "Epoch 1/3\n",
            "64/64 - 38s - loss: 8.3446e-07 - 38s/epoch - 588ms/step\n",
            "Epoch 2/3\n",
            "64/64 - 38s - loss: 8.3446e-07 - 38s/epoch - 587ms/step\n",
            "Epoch 3/3\n",
            "64/64 - 38s - loss: 8.3446e-07 - 38s/epoch - 587ms/step\n",
            "128: 173.1\n",
            "TEST: distilbert-base-uncased at b=256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'vocab_transform', 'vocab_layer_norm', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'dropout_99', 'classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_distil_bert_for_sequence_classification_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " distilbert (TFDistilBertMai  multiple                 66362880  \n",
            " nLayer)                                                         \n",
            "                                                                 \n",
            " pre_classifier (Dense)      multiple                  590592    \n",
            "                                                                 \n",
            " classifier (Dense)          multiple                  6152      \n",
            "                                                                 \n",
            " dropout_99 (Dropout)        multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,959,624\n",
            "Trainable params: 66,959,624\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "FAILED: distilbert-base-uncased at b=256 OOM\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from PIL import Image as im\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "import csv\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "try:\n",
        "    from transformers import TFAutoModelForSequenceClassification\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "tf.config.experimental.set_memory_growth(\n",
        "    tf.config.list_physical_devices(\"GPU\")[0], True\n",
        ")\n",
        "\n",
        "TIME_ID = time.strftime(\"%s\")\n",
        "DATA_DIR = f\"./train/{TIME_ID}/\"\n",
        "\n",
        "\n",
        "def set_precision(dtype_policy):\n",
        "    \"\"\"Default to float32 for compute and variable dtypes. Optionally used float16 for compute, float32 for variable dtypes (\"mixed_float16\")\"\"\"\n",
        "    if dtype_policy == \"fp16\":\n",
        "        policy = mixed_precision.Policy(\"mixed_float16\")\n",
        "        mixed_precision.set_global_policy(policy)\n",
        "    else:\n",
        "        mixed_precision.set_global_policy(\"float32\")\n",
        "\n",
        "\n",
        "def set_xla(enable):\n",
        "    \"\"\"Use the accelerated linear algebra (xla)\"\"\"\n",
        "    tf.config.optimizer.set_jit(enable)\n",
        "\n",
        "\n",
        "def create_synthetic_data(data_dir, img_dim, img_per_label=128, num_labels=16):\n",
        "    \"\"\"Reading images in from the hard drive is more realistic than storing data entirely on GPU VRAM, or creating synthetic data at runtime\"\"\"\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "    for j in tqdm(range(num_labels), desc=\"Creating synthetic data\", unit=\"folders\"):\n",
        "        os.makedirs(f\"{data_dir}/{j}/\")\n",
        "        for i in range(img_per_label):\n",
        "            _make_image(img_dim, f\"{data_dir}/{j}/{j:03}_{i:06}_dummy.png\")\n",
        "\n",
        "    return data_dir\n",
        "\n",
        "\n",
        "def _make_image(img_dim=224, filepath=\"./dummy.png\"):\n",
        "    \"\"\"Helper function to actually create synthetic images for CNN training\"\"\"\n",
        "    rng = np.random.default_rng()\n",
        "    arr = rng.integers(low=0, high=256, size=(img_dim, img_dim, 3), dtype=np.uint8)\n",
        "    img = im.fromarray(arr)\n",
        "    img.save(filepath)\n",
        "\n",
        "\n",
        "def cnn_create(model_name, img_shape, num_labels=16):\n",
        "    if model_name == \"resnet50\":\n",
        "        base_model = tf.keras.applications.resnet50.ResNet50(\n",
        "            input_shape=img_shape, include_top=False, weights=None\n",
        "        )\n",
        "    elif model_name == \"resnet50v2\":\n",
        "        base_model = tf.keras.applications.resnet_v2.ResNet50V2(\n",
        "            input_shape=img_shape, include_top=False, weights=None\n",
        "        )\n",
        "    elif model_name == \"resnet101v2\":\n",
        "        base_model = tf.keras.applications.resnet_v2.ResNet101V2(\n",
        "            input_shape=img_shape, include_top=False, weights=None\n",
        "        )\n",
        "    elif model_name == \"resnet152v2\":\n",
        "        base_model = tf.keras.applications.resnet_v2.ResNet152V2(\n",
        "            input_shape=img_shape, include_top=False, weights=None\n",
        "        )\n",
        "    elif model_name == \"mobilenetv2\":\n",
        "        base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
        "            input_shape=img_shape, include_top=False, weights=None\n",
        "        )\n",
        "    elif model_name == \"inceptionv3\":\n",
        "        base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
        "            input_shape=img_shape, include_top=False, weights=None\n",
        "        )\n",
        "    elif model_name == \"vgg16\":\n",
        "        base_model = tf.keras.applications.vgg16.VGG16(\n",
        "            input_shape=img_shape, include_top=False, weights=None\n",
        "        )\n",
        "    elif model_name == \"vgg19\":\n",
        "        base_model = tf.keras.applications.vgg19.VGG19(\n",
        "            input_shape=img_shape, include_top=False, weights=None\n",
        "        )\n",
        "    else:\n",
        "        exit()\n",
        "\n",
        "    # Specify our own model top, to allow for arbitrary input shapes and num_labels\n",
        "    inputs = tf.keras.Input(shape=img_shape)\n",
        "    x = base_model(inputs, training=True)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = tf.keras.layers.Dense(num_labels, activation=\"softmax\")(x)\n",
        "\n",
        "    # Recompile model to train\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def cnn_benchmark(train_ds, model, batch_size, epochs, warmup=True):\n",
        "    # Warmup\n",
        "    if warmup:\n",
        "        model.fit(train_ds, epochs=2)\n",
        "\n",
        "    # Benchmarking\n",
        "    st = time.time()\n",
        "    model.fit(train_ds, epochs=epochs)\n",
        "    et = time.time()\n",
        "\n",
        "    total_img = int(train_ds.__len__()) * batch_size * epochs\n",
        "    throughput = round(total_img / (et - st), 1)\n",
        "    print(f\"{batch_size}: {throughput}\")\n",
        "\n",
        "    return throughput\n",
        "\n",
        "\n",
        "def cnn_run(models, precision, xla):\n",
        "    # runtime knobs\n",
        "    set_precision(precision)\n",
        "    set_xla(xla)\n",
        "\n",
        "    # model knobs        \n",
        "    SUPPORTED_MODELS = [\n",
        "        \"mobilenetv2\",\n",
        "        \"resnet50\",\n",
        "        \"resnet50v2\",\n",
        "        \"resnet101v2\",\n",
        "        \"resnet152v2\",\n",
        "        \"vgg16\",\n",
        "        \"vgg19\",\n",
        "    ]\n",
        "\n",
        "    for model_name in models:\n",
        "        assert model_name in SUPPORTED_MODELS\n",
        "\n",
        "    BATCH_SIZES = [32, 64, 128, 256]\n",
        "    img_dim = 224\n",
        "\n",
        "    # benchmarking knobs\n",
        "    epochs = 3\n",
        "    warmup = True\n",
        "\n",
        "    # Data logging file\n",
        "    f = open(f\"{TIME_ID}_results.csv\", \"w\", buffering=1)\n",
        "    fieldnames = [\n",
        "        \"model\",\n",
        "        \"batch_size\",\n",
        "        \"img_dims_xy\",\n",
        "        \"precision\",\n",
        "        \"xla\",\n",
        "        \"throughput\",\n",
        "    ]\n",
        "    writer = csv.DictWriter(f, fieldnames)\n",
        "    writer.writeheader()\n",
        "\n",
        "    # create synthetic data once\n",
        "    create_synthetic_data(DATA_DIR, img_dim)\n",
        "\n",
        "    # run benchmarks\n",
        "    for model_name in models:\n",
        "        model = cnn_create(model_name, (img_dim, img_dim, 3))\n",
        "        for batch_size in BATCH_SIZES:\n",
        "            print(f\"TEST: {model_name} at b={batch_size}\")\n",
        "            train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "                DATA_DIR, image_size=(img_dim, img_dim), batch_size=batch_size\n",
        "            )\n",
        "            try:\n",
        "                throughput = cnn_benchmark(train_ds, model, batch_size, epochs, warmup)\n",
        "            except tf.errors.ResourceExhaustedError as e:\n",
        "                print(f\"FAILED: {model_name} at b={batch_size} OOM\")\n",
        "                break\n",
        "\n",
        "            row = [model_name, batch_size, img_dim, precision, xla, throughput]\n",
        "            assert len(row) == len(fieldnames)\n",
        "            writer.writerow({header: value for header, value in zip(fieldnames, row)})\n",
        "\n",
        "\n",
        "def trans_create(model_name, seq_len=128, batch_size=32, steps=30, num_labels=8):\n",
        "    # data\n",
        "    dataset_size = batch_size * steps\n",
        "    example_x = tf.random.uniform(\n",
        "        (seq_len,),\n",
        "        minval=0,\n",
        "        maxval=1000,\n",
        "        dtype=tf.dtypes.int64,\n",
        "    )\n",
        "    example_y = tf.random.uniform(shape=[], minval=0, maxval=num_labels, dtype=tf.int64)\n",
        "    dataset_x = tf.stack([example_x] * dataset_size)\n",
        "    dataset_y = tf.stack([example_y] * dataset_size)\n",
        "    # model\n",
        "    model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name, num_labels=num_labels, cache_dir=\"./cache/\"\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    )\n",
        "    return {\n",
        "        \"sample_data\": [dataset_x, dataset_y],\n",
        "        \"model\": model,\n",
        "    }\n",
        "\n",
        "def trans_benchmark(model, dataset_x, dataset_y, batch_size, epochs, steps=30, warmup=True):\n",
        "    # Warmup\n",
        "    if warmup == True:\n",
        "        _ = model.fit(x=dataset_x, y=dataset_y, batch_size=batch_size, epochs=2, verbose=2)\n",
        "\n",
        "    # Benchmarking\n",
        "    st = time.time()\n",
        "    _ = model.fit(x=dataset_x, y=dataset_y, batch_size=batch_size, epochs=epochs, verbose=2)\n",
        "    et = time.time()\n",
        "\n",
        "    total_img = steps * batch_size * epochs\n",
        "    throughput = round(total_img / (et - st), 1)\n",
        "    print(f\"{batch_size}: {throughput}\")\n",
        "\n",
        "    return throughput\n",
        "\n",
        "def trans_run(models, precision, xla):\n",
        "    # runtime knobs\n",
        "    set_precision(precision)\n",
        "    set_xla(xla)\n",
        "\n",
        "    # model knobs\n",
        "    SUPPORTED_MODELS = [\n",
        "        \"distilbert-base-uncased\",\n",
        "        \"bert-large-uncased\"\n",
        "    ]\n",
        "\n",
        "    for model_name in models:\n",
        "        assert model_name in SUPPORTED_MODELS\n",
        "    BATCH_SIZES = [16, 32, 64, 128, 256]\n",
        "\n",
        "    # benchmarking knobs\n",
        "    warmup = True\n",
        "    steps = 2**6\n",
        "    seq_len = 128\n",
        "    epochs = 3\n",
        "\n",
        "    # Data logging file\n",
        "    f = open(f\"{TIME_ID}_results.csv\", \"w\", buffering=1)\n",
        "    fieldnames = [\n",
        "        \"model\",\n",
        "        \"batch_size\",\n",
        "        \"seqlen\",\n",
        "        \"precision\",\n",
        "        \"xla\",\n",
        "        \"throughput\",\n",
        "    ]\n",
        "    writer = csv.DictWriter(f, fieldnames)\n",
        "    writer.writeheader()\n",
        "\n",
        "    # run benchmarks\n",
        "    for model_name in models:\n",
        "        for batch_size in BATCH_SIZES:\n",
        "            print(f\"TEST: {model_name} at b={batch_size}\")\n",
        "            try:\n",
        "                train_items = trans_create(model_name, seq_len=seq_len, batch_size=batch_size, steps=steps) \n",
        "                model = train_items[\"model\"]\n",
        "                dataset_x, dataset_y = train_items[\"sample_data\"]\n",
        "                model.summary()\n",
        "                throughput = trans_benchmark(model, dataset_x, dataset_y, batch_size, epochs=epochs, steps=steps, warmup=warmup)\n",
        "                \n",
        "                row = [model_name, batch_size, seq_len, precision, xla, throughput]\n",
        "                assert len(row) == len(fieldnames)\n",
        "                writer.writerow({header: value for header, value in zip(fieldnames, row)})\n",
        "            except tf.errors.ResourceExhaustedError as e:\n",
        "                print(f\"FAILED: {model_name} at b={batch_size} OOM\")\n",
        "                break\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    cnn_run([\"resnet50v2\"], \"fp32\", True)\n",
        "    trans_run([\"distilbert-base-uncased\"], \"fp32\", True)\n"
      ]
    }
  ]
}